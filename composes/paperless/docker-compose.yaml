# docker-compose file for running paperless from the docker container registry.
# This file contains everything paperless needs to run.
# Paperless supports amd64, arm and arm64 hardware.
#
# All compose files of paperless configure paperless in the following way:
#
# - Paperless is (re)started on system boot, if it was running before shutdown.
# - Docker volumes for storing data are managed by Docker.
# - Folders for importing and exporting files are created in the same directory
#   as this file and mounted to the correct folders inside the container.
# - Paperless listens on port 8000.
#
# In addition to that, this docker-compose file adds the following optional
# configurations:
#
# - Instead of SQLite (default), PostgreSQL is used as the database server.
# - Apache Tika and Gotenberg servers are started with paperless and paperless
#   is configured to use these services. These provide support for consuming
#   Office documents (Word, Excel, Power Point and their LibreOffice counter-
#   parts.
#
# To install and update paperless with this file, do the following:
#
# - Copy this file as 'docker-compose.yml' and the files 'docker-compose.env'
#   and '.env' into a folder.
# - Run 'docker-compose pull'.
# - Run 'docker-compose run --rm webserver createsuperuser' to create a user.
# - Run 'docker-compose up -d'.
#
# For more extensive installation and update instructions, refer to the
# documentation.

version: "3.4"
services:
  broker:
    image: docker.io/library/redis:8
    restart: unless-stopped
    volumes:
      - ../../volumes/paperless/redis_data:/data
    networks:
      - no-internet

  db:
    image: docker.io/library/postgres:13
    restart: unless-stopped
    volumes:
      - ../../volumes/paperless/postgres_data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: paperless
      POSTGRES_USER: paperless
      POSTGRES_PASSWORD: paperless
    networks:
      - no-internet


  webserver:
    image: ghcr.io/paperless-ngx/paperless-ngx:latest
    restart: unless-stopped
    hostname: webserver
    depends_on:
      - db
      - broker
      - gotenberg
      - tika
    ports:
      - 9843:8000
    healthcheck:
      test: ["CMD", "curl", "-fs", "-S", "--max-time", "2", "http://localhost:8000"]
      interval: 30s
      timeout: 10s
      retries: 5
    volumes:
      - ../../volumes/paperless/data:/usr/src/paperless/data
      - ../../volumes/paperless/media:/usr/src/paperless/media
      - ../../volumes/paperless/export:/usr/src/paperless/export
      - ../../volumes/paperless/consume:/usr/src/paperless/consume
    networks:
      - no-internet

    env_file: docker-compose.env
    environment:
      PAPERLESS_REDIS: redis://broker:6379
      PAPERLESS_DBHOST: db
      PAPERLESS_TIKA_ENABLED: 1
      PAPERLESS_TIKA_GOTENBERG_ENDPOINT: http://gotenberg:3000
      PAPERLESS_TIKA_ENDPOINT: http://tika:9998
      http_proxy: http://squidproxy:8080
      https_proxy: https://squidproxy:8080

  gotenberg:
    image: docker.io/gotenberg/gotenberg:8.20
    restart: unless-stopped
    networks:
      - no-internet

    # The gotenberg chromium route is used to convert .eml files. We do not
    # want to allow external content like tracking pixels or even javascript.
    command:
      - "gotenberg"
      - "--chromium-disable-javascript=true"
      - "--chromium-allow-list=file:///tmp/.*"

  tika:
    image: docker.io/apache/tika:latest
    restart: unless-stopped
    networks:
      - no-internet

  nginx:
    image: nginx
    depends_on:
      - webserver
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf
    ports:
      - "7777:8080"
    networks:
      - web
      - no-internet

  proxy:
    image: ubuntu/squid
    restart: always
    hostname: squidproxy
    ports:
      - "7778:8080"
      - "7779:3128"
    volumes:
      - ./squid.conf:/etc/squid/squid.conf
    networks:
      - web
      - no-internet

  cryptomator:
    build: .
    env_file: crypto.env
    volumes:
      - ../../volumes/paperless/vault:/vaults/vault
    networks:
      - no-internet
      #- web
    ports:
      - "18080:8080"

  rclone:
    depends_on:
      - cryptomator
      - webserver
    image: rclone/rclone:latest
    restart: "no"
    #deploy:
      #replicas: 1
      #restart_policy:
        # rclone runs and exit, we emulate cron by restarting it every 50s
        #condition: always
        #condition: any
        #delay: 10m
    command:
      - "sync"
      - "--auto-confirm"
      - "/data/documents/archive"
      - "crypto:archive"
    volumes:
      - ./rclone:/config/rclone
      - ../../volumes/paperless/media:/data
    networks:
      - no-internet

  paperless-gpt:
    # Use one of these image sources:
    image: icereed/paperless-gpt:latest  # Docker Hub
    # image: ghcr.io/icereed/paperless-gpt:latest  # GitHub Container Registry
    environment:
      PAPERLESS_BASE_URL: "http://webserver:8000"
      PAPERLESS_API_TOKEN: "85749bcb62ad05624ec92d6f3c3d888beee51c9f"
      # PAPERLESS_PUBLIC_URL: "http://paperless.mydomain.com" # Optional
      MANUAL_TAG: "paperless-gpt" # Optional, default: paperless-gpt
      AUTO_TAG: "paperless-gpt-auto" # Optional, default: paperless-gpt-auto
      # LLM Configuration - Choose one:
      
      # Option 1: Standard OpenAI
      # LLM_PROVIDER: "ollama"
      # LLM_MODEL: "gemma3:4b"
      # OPENAI_API_KEY: "your_openai_api_key"
      
      # Option 2: Mistral
      # LLM_PROVIDER: "mistral"
      # LLM_MODEL: "mistral-large-latest"
      # MISTRAL_API_KEY: "your_mistral_api_key"

      # Option 3: Azure OpenAI
      # LLM_PROVIDER: "openai"
      # LLM_MODEL: "your-deployment-name"
      # OPENAI_API_KEY: "your_azure_api_key"
      # OPENAI_API_TYPE: "azure"
      # OPENAI_BASE_URL: "https://your-resource.openai.azure.com"
      
      # Option 3: Ollama (Local)
      LLM_PROVIDER: "ollama"
      LLM_MODEL: "deepseek-r1:8b"
      # OLLAMA_HOST: "http://host.docker.internal:11434"
      TOKEN_LIMIT: 1000 # Recommended for smaller models
      
      # Optional LLM Settings
      # LLM_LANGUAGE: "English" # Optional, default: English

      # OCR Configuration - Choose one:
      # Option 1: LLM-based OCR
      OCR_PROVIDER: "llm" # Default OCR provider
      VISION_LLM_PROVIDER: "ollama" # openai or ollama
      # VISION_LLM_MODEL: "minicpm-v" # minicpm-v (ollama) or gpt-4o (openai)
      VISION_LLM_MODEL: "gemma3:4b"
      OLLAMA_HOST: "http://host.docker.internal:11434" # If using Ollama

      # OCR Processing Mode
      OCR_PROCESS_MODE: "image" # Optional, default: image, other options: pdf, whole_pdf
      PDF_SKIP_EXISTING_OCR: "false" # Optional, skip OCR for PDFs with existing OCR

      # Option 2: Google Document AI
      # OCR_PROVIDER: 'google_docai'       # Use Google Document AI
      # GOOGLE_PROJECT_ID: 'your-project'  # Your GCP project ID
      # GOOGLE_LOCATION: 'us'              # Document AI region
      # GOOGLE_PROCESSOR_ID: 'processor-id' # Your processor ID
      # GOOGLE_APPLICATION_CREDENTIALS: '/app/credentials.json' # Path to service account key

      # Option 3: Azure Document Intelligence
      # OCR_PROVIDER: 'azure'              # Use Azure Document Intelligence
      # AZURE_DOCAI_ENDPOINT: 'your-endpoint' # Your Azure endpoint URL
      # AZURE_DOCAI_KEY: 'your-key'        # Your Azure API key
      # AZURE_DOCAI_MODEL_ID: 'prebuilt-read' # Optional, defaults to prebuilt-read
      # AZURE_DOCAI_TIMEOUT_SECONDS: '120'  # Optional, defaults to 120 seconds
      # AZURE_DOCAI_OUTPUT_CONTENT_FORMAT: 'text' # Optional, defaults to 'text', other valid option is 'markdown'
              # 'markdown' requires the 'prebuilt-layout' model

      # Enhanced OCR Features
      CREATE_LOCAL_HOCR: "false" # Optional, save hOCR files locally
      LOCAL_HOCR_PATH: "/app/hocr" # Optional, path for hOCR files
      CREATE_LOCAL_PDF: "false" # Optional, save enhanced PDFs locally
      LOCAL_PDF_PATH: "/app/pdf" # Optional, path for PDF files
      PDF_UPLOAD: "false" # Optional, upload enhanced PDFs to paperless-ngx
      PDF_REPLACE: "false" # Optional and DANGEROUS, delete original after upload
      PDF_COPY_METADATA: "true" # Optional, copy metadata from original document
      PDF_OCR_TAGGING: "true" # Optional, add tag to processed documents
      PDF_OCR_COMPLETE_TAG: "paperless-gpt-ocr-complete" # Optional, tag name

      # Option 4: Docling Server
      # OCR_PROVIDER: 'docling'              # Use a Docling server
      # DOCLING_URL: 'http://your-docling-server:port' # URL of your Docling instance

      AUTO_OCR_TAG: "paperless-gpt-ocr-auto" # Optional, default: paperless-gpt-ocr-auto
      OCR_LIMIT_PAGES: "5" # Optional, default: 5. Set to 0 for no limit.
      LOG_LEVEL: "info" # Optional: debug, warn, error
    volumes:
      - ./prompts:/app/prompts # Mount the prompts directory
      # For Google Document AI:
      - ${HOME}/.config/gcloud/application_default_credentials.json:/app/credentials.json
      # For local hOCR and PDF saving:
      # - ./hocr:/app/hocr # Only if CREATE_LOCAL_HOCR is true
      # - ./pdf:/app/pdf # Only if CREATE_LOCAL_PDF is true
    ports:
      - "7808:8080"
    depends_on:
      - webserver
    networks:
      - web
      - no-internet
  
  # paperless-ai:
  #   image: clusterzx/paperless-ai
  #   container_name: paperless-ai
  #   networks:
  #     - web
  #     - no-internet
  #   restart: unless-stopped
  #   cap_drop:
  #     - ALL
  #   security_opt:
  #     - no-new-privileges=true
  #   environment:
  #     - PUID=1000
  #     - PGID=1000
  #     - PAPERLESS_AI_PORT=${PAPERLESS_AI_PORT:-3000}
  #     - RAG_SERVICE_URL=http://localhost:8000
  #     - RAG_SERVICE_ENABLED=true
  #   ports:
  #     - "3000:${PAPERLESS_AI_PORT:-3000}"
  #   volumes:
  #     - paperless-ai_data:/app/data

volumes:
  data:
  media:
  pgdata:
  redisdata:
  paperless-ai_data:

networks:
  web:
    driver: bridge
  no-internet:
    driver: bridge
    internal: true # block internet access
